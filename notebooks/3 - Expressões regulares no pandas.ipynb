{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uma introdução à Expressões Regulares\n",
    "\n",
    "As expressões regulares (*regular expressions*, em inglês) são uma ferramenta poderosa quando trabalhamos com dados textuais.\n",
    "\n",
    "Para introduzir sua relevância vamos partir de um exemplo simples, mas que ilustra bem a limitação de trabalhar com strings diretamente.\n",
    "\n",
    "Suponha que você deseja desenvolver uma ferramenta para checar o resultado de decisões judiciais. Seu objetivo é identificar se uma decisão é favorável ou não ao pedido do autor. Ainda que não possamos saber exatamente como o juiz irá redigir sua decisão, usamos um conjunto limitado de termos que nos permitem identificar o resultado. Por exemplo, o dispositivo da decisão informará se o pedido ou recurso é \"procedente\"/\"improcedente\" ou \"deferido\"/\"indeferido\".\n",
    "\n",
    "Uma ideia inicialmente promissora seria checar se a string contém a palavra \"procedente\" ou \"deferido\". Isso pode ser facilmente feito com o uso do operador `in` do Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sendo assim, em face das razões expostas, com fundamento nos \n",
      "poderes processuais outorgados ao Relator da causa (RTJ 139/53 – \n",
      "RTJ 168/174), e considerando, ainda, os precedentes firmados pelo \n",
      "Plenário desta Suprema Corte, julgo IMPROCEDENTE a presente ação de \n",
      "mandado de segurança, restando prejudicado, em consequência, o exame \n",
      "dos embargos de declaração opostos pelo impetrante.\n"
     ]
    }
   ],
   "source": [
    "decisao_improcedencia = \"\"\"Sendo assim, em face das razões expostas, com fundamento nos \n",
    "poderes processuais outorgados ao Relator da causa (RTJ 139/53 – \n",
    "RTJ 168/174), e considerando, ainda, os precedentes firmados pelo \n",
    "Plenário desta Suprema Corte, julgo IMPROCEDENTE a presente ação de \n",
    "mandado de segurança, restando prejudicado, em consequência, o exame \n",
    "dos embargos de declaração opostos pelo impetrante.\"\"\"\n",
    "\n",
    "print(decisao_improcedencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos fazer nosso teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"IMPROCEDENTE\" in decisao_improcedencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um primeiro resultado promissor. O operador in checa se uma string está contida da outra. Você consegue imaginar algum problema com essa abordagem?\n",
    "\n",
    "Vamos testar com uma nova string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"PROCEDENTE\" in decisao_improcedencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que temos um problema. O termo \"procedente\" também está contido na decisão. Isso acontece porque as operações com strings são feitas caracter a caracter, o Python não identifica palavras inteiras. Teríamos o mesmo problema com o termo \"deferido\".\n",
    "\n",
    "Poderíamos pensar em formas de resolver esse problema. Por exemplo, dividindo o texto em palavras, mas vamos ver que as expressões regulares são uma ferramenta mais poderosa e flexível para resolver esse tipo de problema. Aprendendo suas regras, podemos lidar com esses casos e outros com códigos mais eficientes.\n",
    "\n",
    "Vamos começar importando a biblioteca `re` do Python, e vendo como poderíamos lidar com o problema usando a função `search`, que busca pela expressão criada em uma string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(233, 243), match='PROCEDENTE'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "identificador_procedencia = re.compile(r\"PROCEDENTE\")\n",
    "\n",
    "re.search(identificador_procedencia, decisao_improcedencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, parece que ainda temos o mesmo problema e não tivemos nenhum ganho. Nosso código apenas ficou mais complicado.\n",
    "\n",
    "Mas agora que criamos nossa primeira regex vamos poder resolver o rpoblema facilmente.\n",
    "\n",
    "Antes disso, uma breve explicação do código.\n",
    "\n",
    "Primeiro, compilamos a expressão regular com a função `re.compile`. Isso divide nossa tarefa em 2 partes, primeiro criar o objeto da regex e depois usá-lo para buscar em strings.\n",
    "\n",
    "Quando escrevemos uma regex é importasnte semrpe adicionarmos o prefixo `r` antes da string. Isso evita que o Python interprete caracteres especiais como parte da string. Além do texto, podemos usar sequência de escape para representar grupos de caracteres ou estabeler detalhes de como essa string deve aparecer.\n",
    "\n",
    "Por exemplo, `\\d` representa qualquer dígito (algarismo), `\\w` qualquer caractere alfanumérico, e `\\s` qualquer espaço em branco. Podemos usar também letras maiúsculas para representar o oposto, por exemplo `\\D` representa qualquer caractere que não seja um dígito.\n",
    "\n",
    "No nosso caso, podemos usar a expressar regular `r\"\\bprocedente\\b\"` para buscar a palavra \"procedente\" como uma palavra inteira. O `\\b` representa uma borda de palavra, ou seja, o início ou fim de uma palavr. O módulo identifica automaticamente os limites de palavra para nós! Assim, iremos procurar apenas a palavra \"procedente\" e não qualquer string que contenha essa palavra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "identificador_procedencia = re.compile(r\"\\bPROCEDENTE\\b\")\n",
    "\n",
    "re.search(identificador_procedencia, decisao_improcedencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A princípio podemos achar que tivemos algo ainda pior. Isso acontece pois o método `search` retorna um objeto `Match` que contém informações sobre a posição da string encontrada. Porém, quando ele não encontrada nada ele retorna um objeto `None`. Esse objeto não é exibido pelo Jupyter!\n",
    "\n",
    "Então o fato da célular não exibir nenhum output significa que nosso código funcionou corretamente, e não encontramos a palavra \"procedente\" na string como desejávamos!\n",
    "\n",
    "Agora, vamos criar a expressão para identificar a decisão como improcedente. Vamos introduzir outra ferramenta de expressões regulares: as flags, em especial a flag `re.IGNORECASE` ou `re.I`.\n",
    "\n",
    "Isso permite que a expressão que criamos ignore a diferença entre letras maiúsculas e minúsculas. Assim, podemos buscar por \"improcedente\" ou \"IMPROCEDENTE\" ou \"ImPrOcEdEnTe\" sem nos preocuparmos com a formatação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(231, 243), match='IMPROCEDENTE'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_improcedencia = re.compile(r\"\\bimprocedente\\b\", re.I)\n",
    "\n",
    "re.search(id_improcedencia, decisao_improcedencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar no objeto `match` que a expressão encontrada foi `IMPROCEDENTE`. O span nos informa a posição inicial e final da string encontrada.\n",
    "\n",
    "Outra parte importante no uso de regex é definir padrões. Para isso precisamos fazer uso mais extenso da sintaxe do módulo:\n",
    "\n",
    "## Lista de expressões regulares:\n",
    "\n",
    " Tipos de caracteres:\n",
    "- `.` - Qualquer caractere exceto nova linha\n",
    "\n",
    "- `\\d` - Dígito (0-9)\n",
    "\n",
    "- `\\D` - Qualquer coisa que não seja um dígito (0-9)\n",
    "\n",
    "- `\\w` - \"Word Character\" (a-z, A-Z, 0-9, _)\n",
    "\n",
    "- `\\W` - Qualquer coisa que não seja um \"Word Character\"\n",
    "\n",
    "- `\\s` - Espaços em branco (espaço, tab, nova linha)\n",
    "\n",
    "- `\\S` - Qualquer coisa que não seja um espaço em branco\n",
    "\n",
    " Limites/Posição:\n",
    "- `\\b` - Limite de palavra\n",
    "\n",
    "- `\\B` - Meio de palavra\n",
    "\n",
    "- `^` - Início de uma string\n",
    "\n",
    "- `$` - Fim de uma string\n",
    "\n",
    "Quantificadores de caracter ou grupo:\n",
    "- `*` - 0 ou mais\n",
    "- `+` - 1 ou mais\n",
    "- `?` - 0 ou 1 vez\n",
    "- `{3}` - Exatamente 3\n",
    "- `{3,4}` - De 3 a 4 {mínimo, máximo}\n",
    "\n",
    "\n",
    "Uma lista completa (em inglês) desses caracteres e da sintaxe de Regex pode ser encontrada na documentação do módulo: [https://docs.python.org/3/library/re.html#regular-expression-syntax](https://docs.python.org/3/library/re.html#regular-expression-syntax)\n",
    "\n",
    "\n",
    "## Usando padrões\n",
    "\n",
    "Imaginemos que queremos criar uma expressão regular que identifique e extraia qualquer CPF de um texto. O padrão de um CPF é `XXX.XXX.XXX-XX`, onde `X` é um dígito de 0 a 9.\n",
    "\n",
    "Vamos ignorar que existe uma verificação de digita para verificar se um CPF é válido. Nosso objetivo é apenas identificar o padrão.\n",
    "\n",
    "Podemos criar um padrão para isso. Uma primeira forma é manter todo padrão substituindo o número por `\\d`, que irá representar qualquer algarismo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_cpf1 = re.compile(r\"\\d\\d\\d\\.\\d\\d\\d\\.\\d\\d\\d-\\d\\d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ponto importante é que precisamos escapar o `.` com uma barra invertida `\\`, pois o ponto é um caractere especial em regex (que representa qualquer caractere). Se não fizermos isso, o ponto será interpretado como qualquer caractere, e não como um ponto literal!\n",
    "\n",
    "Agora podemos testar nossa expressão regular em uma string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "um_cpf = \"123.456.789-00\"\n",
    "\n",
    "algo_parecido_com_cpf = \"123.45A.789-00\"\n",
    "\n",
    "qualificacao_processual = \"\"\"\n",
    "Tício da Silva, brasileiro, casado, advogado,\n",
    "inscrito no CPF sob o n.º 754.456.057-03 [...]\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 14), match='123.456.789-00'>\n",
      "None\n",
      "<re.Match object; span=(73, 87), match='754.456.057-03'>\n"
     ]
    }
   ],
   "source": [
    "print(re.search(re_cpf1, um_cpf))\n",
    "print(re.search(re_cpf1, algo_parecido_com_cpf))\n",
    "print(re.search(re_cpf1, qualificacao_processual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que realmente isso só nos retorna o match quando a expressão segue o padrão do CPF. Outras casos que poderíamos registrar do mesmo modo são precedentes ou número do CNJ. Vamos abordar isso na próxima seção, integrando a expressão regular ao Pandas.\n",
    "\n",
    "Para sua prática, abaixo temos formas diferentes de identificar o mesmo padrão de CPF. Tente explicar o funcionamento de cada uma delas. Para te ajudar, use o site www.regex101.com, que explica a expressão regular e deixa você testá-la com multiplas strings ao mesmo tempo.\n",
    "\n",
    "Deixamos um link preparado com alguns exemplos em: [https://regex101.com/r/oYI2nF/1](https://regex101.com/r/oYI2nF/1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpf_alternativo = re.compile(r\"\\d{3}\\.\\d{3}\\.\\d{3}-\\d{2}\")\n",
    "alternativa2 = re.compile(r\"(\\d{3}\\.){2}\\d{3}-\\d{2}\")\n",
    "alternativa3 = re.compile(r\"[0-9]{3}\\.[0-9]{3}\\.[0-9]{3}-[0-9]{2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso você queira se aprofundar um pouco mais no uso do pacote RE no python, você pode checar esse notebook que aborda em mais detalhes o uso de expressões regulares: [Expressões Regulares no Python: https://github.com/joseluizn/progr-adv-fgvdireitorio/blob/main/apostila/Apostila%20-%20Programa%C3%A7%C3%A3o%20para%20Advogados%20-%20Aula%2010%20e%20Aula%2011.ipynb](https://github.com/joseluizn/progr-adv-fgvdireitorio/blob/main/apostila/Apostila%20-%20Programa%C3%A7%C3%A3o%20para%20Advogados%20-%20Aula%2010%20e%20Aula%2011.ipynb)\n",
    "\n",
    "# Expressões regulares no Pandas\n",
    "\n",
    "*Recomendamos que você use o site [regex101.com](https://regex101.com/) para testar suas expressões regulares e acompanhar as expressões regulares apresentadas aqui quando tiver uma dúvida. O site é muito útil, lembre-se apenas de selecionar o modo Python do lado esquerdo.*\n",
    "\n",
    "Para usar expressões regulares dentro do pandas, precisar acessar os métodos que lidam com strings. Essas funcionalidades são flexíveis e permitem fazer buscas tanto por strings literais quanto por expressões regulares.\n",
    "\n",
    "Assim, vamos sempre trabalhar diretamente com a coluna de texto relevante, já que vamos fazer buscas em strings. Sempre que selecionarmos uma coluna, devemos seguir com a indicação de que estamos lidando com strings, usando o `.str` e então o método que desejamos aplicar.\n",
    "\n",
    "Abaixo listamos alguns dos métodos mais relevantes, para uma listagem completa consulte a lista de métodos para strings no Pandas: [https://pandas.pydata.org/docs/reference/series.html#string-handling](https://pandas.pydata.org/docs/reference/series.html#string-handling)\n",
    "\n",
    "- [`str.contains()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html): Verifica se uma string contém uma string ou expressão regular. Retorna uma série booleana (True/False). Nós utilizamos esse método em nossa primeira aula para identificar casos de cloroquina nas compras do governo federal;\n",
    "- [`str.count()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.count.html): Conta o número de ocorrências de uma string ou expressão regular;\n",
    "- [`str.extractall()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extractall.html): Extrai todas as ocorrências de uma expressão regular em uma série;\n",
    "\n",
    "Vamos começar nossa aula explorando um pouco mais o método `contains`, que permite checar se uma expressão está presente na coluna. Vamos, antes disso, introduzir nosso próximo caso de estudo.\n",
    "\n",
    "## Ementas do Supremo Tribunal Federal\n",
    "\n",
    "Para explorar o uso de expressões regulares nessas aulas, separamos um dataset contendo emendas de decisões do Supremo Tribunal Federal que mencionam liberdade de expressão, ou remoção de conteúdo. O dataset foi retirado da busca de jurisprudência do STF: https://jurisprudencia.stf.jus.br/pages/search\n",
    "\n",
    "Vamos começar carregando o conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 729 entries, 0 to 728\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Titulo              729 non-null    object\n",
      " 1   Relator             728 non-null    object\n",
      " 2   Data de publicação  727 non-null    object\n",
      " 3   Data de julgamento  728 non-null    object\n",
      " 4   Órgão julgador      729 non-null    object\n",
      " 5   Ementa              729 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 34.3+ KB\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://github.com/joseluizn/cdj-fgvdireitorio/raw/refs/heads/main/notebooks/dados/lib_expressao_11_24.csv\")\n",
    "\n",
    "df.info(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar com uma estrutura simples para identificar se alguma ementa menciona a ADPF 130, que é a ação que julgou a constitucionalidade da Lei de Imprensa. Vamos usar a expressão regular `r\"ADPF 130\"` para buscar essa expressão. Por enquanto, nossa expressão identifica exatamente como escrevemos. Mas mudaremos isso em breve.\n",
    "\n",
    "Vamos salvar o resultado na coluna `cita_adpf130` e verificar quantas ementas mencionam essa ação.\n",
    "\n",
    "Para isso podemos usar o método já conhecido `str.contains`, vamos inicialmente apenas contar quantos casos o citam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(106)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Ementa\"].str.contains(r\"ADPF 130\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma observação antes de continuar: Podemos somar uma coluna de booleanos para obter o número de casos que são verdadeiros mesmo sem converter explicitamente para `int` ou `float`. Isso acontece pois o Python interpreta `True` como 1 e `False` como 0. Assim, ao somar uma coluna de booleanos, obtemos o número de de linhas nas quais a variável é verdadeira.\n",
    "\n",
    "\n",
    "Além disso, vale checarmos os argumentos padrão do método:\n",
    "\n",
    "1. `case=True` - O que significa que por padrão a função diferencia entre maiúsculas e minúsculas. Se quisermos ignorar essa diferença, podemos passar `case=False`;\n",
    "2. `regex=True` - Por padrão, a função interpreta o que passamos como uma expressão regular. Isso significa que nas primeiras aulas o que informamos foi interpretado como uma expressão regular. Se quisermos buscar por uma string literal, devemos passar `regex=False`.\n",
    "\n",
    "\n",
    "Vamos compilar uma regex para alterar 2 comportamentos:\n",
    "\n",
    "1. Ignorar a diferença entre maiúsculas e minúsculas, usando a flag `re.IGNORECASE` ou `re.I`;\n",
    "2. Substituir o caractere de espaço por `\\s`, que representa qualquer espaço em branco, incluindo espaços, tabulações e quebras de linha. Isso permite identificar por exemplo se a numeração ficar numa linha separada da sigla da classe.\n",
    "\n",
    "Vamos também salvar o resutlado na coluna `cita_adpf_130`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(106)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lei_imprensa = re.compile(r\"ADPF\\s130\", re.I)\n",
    "\n",
    "df[\"cita_adpf_imprensa\"] = df[\"Ementa\"].str.contains(lei_imprensa).astype(int)\n",
    "\n",
    "# ATENÇÃO: o sum foi removido após o contains.\n",
    "df[\"cita_adpf_imprensa\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não tivemos nenhum ganho. Mas isso nos coloca em um caminho para criar uma regex muito mais poderosa.\n",
    "\n",
    "#### Exercício\n",
    "\n",
    "Antes de prosseguirmos, crie uma expressão regular e identifique o número de linhas que mencionam a ADI 3937."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seu código aqui\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expandindo os casos extraídos.\n",
    "\n",
    "Vamos agora identificar se as ementas mencionam uma ADI qualquer.\n",
    "\n",
    "Isso nos leva a um problema inicial, como fazer se não sabemos o número da ADI? Por sorte, podemos resolver isso facilmente com regex, em vez de buscar pelo número vamos buscar por uma sequência de algarismos com `\\d`, vamos adicionar o quantificador `+` para indicar que queremos um ou mais dígitos, já que nem todos os casos terão o mesmo tamanho de numeração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(39)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "busca_adi = re.compile(r\"ADI\\s\\d+\", re.I)\n",
    "\n",
    "df[\"Ementa\"].str.contains(busca_adi).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que 39 casos mencionam uma ADI. Contudo, você consegue identificar algum problema com o que fizemos até agora? Estamos identificando todas as formas de escrever ADIs e sua numeração?\n",
    "\n",
    "Responda se a expressão atual teria algum problema com os dois casos abaixo:\n",
    "\n",
    "- \"ADI 4.567\"\n",
    "- \"ADI nº 4.567\"\n",
    "- \"ADI n. 4.567\"\n",
    "\n",
    "Você pode visualizar esses exemplos nesse link: [https://regex101.com/r/qiDBGq/1](https://regex101.com/r/qiDBGq/1)\n",
    "\n",
    "Para lidar com essas limitações precisamos de duas alterações. Em primeiro lugar, para identificar corretamente a numeração da ADI, vamos buscar tanto por `\\d` quanto por `\\.`, literalmente. Assim, garantimos que vamos identificar corretamente números com milhares. Para fazer isso, podemos informar que queremos o conjunto de caracteres `[\\d\\.]*\\d`, que representa qualquer dígito ou ponto 0 ou mais vezes, seguido de um dígito (já que a numeração sempre terá um digito no fim).\n",
    "\n",
    "Além disso, vamos adicionar uma parte da expressão regular que pode identificar tanto o \"nº\" quanto o \"n.\" como separadores. Contudo, esse grupo deve ser opcional, já que nem todas as citações vão usar essa formatação. Para isso, vamos adicionar o grupo `(\\sn.?)?` que representa um espaço, seguido de \"n\" e um ponto, e o ponto é opcional. Isso garante que a expressão regular vai identificar tanto \"nº\" quanto \"n.\" como separadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jlnun\\AppData\\Local\\Temp\\ipykernel_15036\\304014132.py:3: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[\"Ementa\"].str.contains(adi_correta).sum()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(52)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adi_correta = re.compile(r\"ADI(\\sn.)?\\s[\\d\\.]*\\d\", re.I)\n",
    "\n",
    "df[\"Ementa\"].str.contains(adi_correta).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obs: O código acima gera um Aviso (`UserWarning`), você pode ignorá-lo.\n",
    "\n",
    "Identificamos mais 13 casos que citam ADIns, 33% de melhora!\n",
    "\n",
    "Vamos agora alterar nossa expressão para mais uma melhora em nossa expressão. Além de identificar ADI, vamos agora ser capazes de identificar qualquer ação de Controle Concentrado.\n",
    "\n",
    "Para isso precisamos usar mais um recurso dentro de um outro grupo (identificado por `()`). Vamos usar o operador `|` para indicar que queremos buscar por uma expressão ou outra. Assim, vamos buscar criar um grupo para a sigla que busca por ADI ou ADPF ou ADC ou ADO. Vamos substituir o trecho `ADI` por `(ADI|ADPF|ADC|ADO)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jlnun\\AppData\\Local\\Temp\\ipykernel_15036\\2395929729.py:2: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[\"Ementa\"].str.contains(re_cont_concentrado).sum()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(176)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_cont_concentrado = re.compile(r\"(ADI|ADPF|ADO|ADC)(\\sn.)?\\s[\\d\\.]*\\d\", re.I)\n",
    "df[\"Ementa\"].str.contains(re_cont_concentrado).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um achado até agora: Parece que a maioria dos casos que citam controle concentrado mencionam a ADPF 130.\n",
    "\n",
    "Encontramso 165 casos que citam ADIs, 105 que citam a ADPF e 165 que citam qualquer ação de controle concentrado. Atenção que um mesmo caso pode cair em mais de uma categoria.\n",
    "\n",
    "Se mudarmos o método do `contains` para `count`, podemos ver quantas citações cada ementa faz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    729.000000\n",
       "mean       0.534979\n",
       "std        1.191406\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.000000\n",
       "max       10.000000\n",
       "Name: n_cits_cont_concentrado, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"n_cits_cont_concentrado\"] = df[\"Ementa\"].str.count(re_cont_concentrado)\n",
    "\n",
    "df[\"n_cits_cont_concentrado\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(390)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"n_cits_cont_concentrado\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtivemos uma quantidade de informações interessante. A grande maioria das ementas não parece citar casos passados desse tipo de jurisdição. Contudo, algumas ementas citam mais de uma vez esses casos, chegando até 10 citações.\n",
    "\n",
    "Vamos agora dar mais um passo em nosso uso de expressões regulares no pandas: vamos extrair as citações a esses casos usando o método `str.extractall`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>ADPF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>ADPF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADPF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADPF</td>\n",
       "      <td>nº</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADPF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">681</th>\n",
       "      <th>2</th>\n",
       "      <td>ADPF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADI</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADI</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ADI</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ADI</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0    1\n",
       "    match           \n",
       "2   0      ADPF  NaN\n",
       "4   0      ADPF  NaN\n",
       "    1      ADPF  NaN\n",
       "    2      ADPF   nº\n",
       "    3      ADPF  NaN\n",
       "...         ...  ...\n",
       "681 2      ADPF  NaN\n",
       "    3       ADI  NaN\n",
       "    4       ADI  NaN\n",
       "    5       ADI  NaN\n",
       "    6       ADI  NaN\n",
       "\n",
       "[390 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Ementa'].str.extractall(re_cont_concentrado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma reação inicial que poderíamos ter é de que nossso código tem um problema. Afinal, além do formato ligeiramente estranho resultante, não temos o número de fato da ação.\n",
    "\n",
    "Isso se deve ao funcionamento do `extractall`. \n",
    "\n",
    "Primeiro, ele retorna um DataFrame com um índice (número ao lado esquerdo das linhas) que indica a linha original de onde o resultado foi obtido. Linhas sem match identificado são ignoradas.\n",
    "\n",
    "Ainda, ele retorna um `DataFrame` com uma coluna para cada grupo de captura que criamos, delimitado pelos parênteses `()`.\n",
    "\n",
    "Assim, se quisermos extrair o número em nosso resultado, podemos adicionar a parte que captura o número da ação dentro de um grupo de captura:\n",
    "\n",
    "Vamos salvar esse resultado em uma nova variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>ADPF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>ADPF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADPF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1    2\n",
       "  match                \n",
       "2 0      ADPF  NaN  130\n",
       "4 0      ADPF  NaN  130\n",
       "  1      ADPF  NaN  130"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracao_concentrado = re.compile(r\"(ADI|ADPF|ADO|ADC)(\\sn.)?\\s([\\d\\.]*\\d)\", re.I)\n",
    "\n",
    "precedentes = df['Ementa'].str.extractall(extracao_concentrado)\n",
    "\n",
    "precedentes.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com esse resultado, incluindo algumas manipulações, poderíamos juntar as informações com o DataFrame original para criar um novo conjunto de dados sobre os casos citados. Isso é assunto para a próxima aula.\n",
    "\n",
    "Um ponto importante é que se você olhar o resultado, poderá ver que a ADPF 130 parece ser citada múltiplas vezes na ementa do caso da linha de id `4`. Isso acontece já que o mesmo texto pode mencionar o caso múltiplas vezes.\n",
    "\n",
    "Isso pode ou não ser relevante para o resultado que queremos alcançar. Caso queiramos contar o número de casos no qual a ação foi citada, deveríamos resolver isso antes de contar as citações.\n",
    "\n",
    "Um último exemplo fazendo um uso um pouco mais elaborado das expressões regulares nos permite lidar com dois problemas dos dados acima:\n",
    "\n",
    "1. Queremos identificar os casos que usam a sinalização de número (nº ou n.), mas essa informação não é importante em nosso resultado;\n",
    "2. Podemos identificar as colunas por um nome já junto a extração.\n",
    "\n",
    "Para fazer isso precisamos de um recurso de manipulação dos grupos de regex.\n",
    "\n",
    "Para lidar com o ponto 1, poderíamos introduzir a expressão `?:` no início do grupo de captura que identifica a sinalização de número. Isso faz com que o grupo não seja retornado no resultado. Assim, podemos identificar a sinalização de número sem precisar incluí-la no resultado.\n",
    "\n",
    "Veja:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>ADPF</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>ADPF</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADPF</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADPF</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADPF</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">681</th>\n",
       "      <th>2</th>\n",
       "      <td>ADPF</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADI</td>\n",
       "      <td>2.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADI</td>\n",
       "      <td>2.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ADI</td>\n",
       "      <td>3.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ADI</td>\n",
       "      <td>3.937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0      1\n",
       "    match             \n",
       "2   0      ADPF    130\n",
       "4   0      ADPF    130\n",
       "    1      ADPF    130\n",
       "    2      ADPF    130\n",
       "    3      ADPF    130\n",
       "...         ...    ...\n",
       "681 2      ADPF    101\n",
       "    3       ADI  2.396\n",
       "    4       ADI  2.656\n",
       "    5       ADI  3.937\n",
       "    6       ADI  3.937\n",
       "\n",
       "[390 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entracao_sem_n = re.compile(r\"(ADI|ADPF|ADO|ADC)(?:\\sn.)?\\s([\\d\\.]*\\d)\", re.I)\n",
    "\n",
    "df['Ementa'].str.extractall(entracao_sem_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ter os dados ainda mais limpos, poderíamos também usar grupos nomeados. Para isso, temos que sinalizar de forma semelhante o grupo que desejamos nomear: `(?P<name>...)`, onde `name` é o nome que queremos dar ao grupo.\n",
    "\n",
    "Vamos modificar nossa expressão regular uma última vez:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sigla</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>ADPF</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>ADPF</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADPF</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sigla  num\n",
       "  match           \n",
       "2 0      ADPF  130\n",
       "4 0      ADPF  130\n",
       "  1      ADPF  130"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_conc_nomeado = re.compile(r\"(?P<sigla>ADI|ADPF|ADO|ADC)(?:\\sn.)?\\s(?P<num>[\\d\\.]*\\d)\", re.I)\n",
    "\n",
    "precs_nomeados = df['Ementa'].str.extractall(cont_conc_nomeado)\n",
    "\n",
    "precs_nomeados.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desafio\n",
    "\n",
    "Um aspecto importante desse merge que fizemos foi que ele resultou em uma alteração da unidade de análise no `DataFrame`. Antes, cada linha representava uma decisão colegiada do STF.\n",
    "\n",
    "E agora qual a unidade de análise?\n",
    "\n",
    "Uma opção comum nos estudos elaborados na FGV Direito Rio com citação a decisões passadas e remover menções duplicadas a um mesmo processo oriundas de uma mesma decisão.\n",
    "\n",
    "Poderíamos alcançar isso com a seguinte linha de código:\n",
    "\n",
    "```python\n",
    "df_com_cits = df_com_cits.drop_duplicates(subset=[\"Titulo\", 0])\n",
    "# ou equivalente\n",
    "df_com_cits.drop_duplicates(subset=[\"Titulo\", 0], inplace=True)\n",
    "```\n",
    "\n",
    "Qual é a unidade de análise resultante desse processo? O que estaríamos contando em cada caso se contarmos o número de linhas contendo ADPF 130 na coluna `0`?\n",
    "\n",
    "#### Exercício\n",
    "\n",
    "Renomeie as colunas `\"match\"` e `0` do DataFrame `df_com_cits`. Você deve usar o método `rename`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juntando os dois conjuntos de dados\n",
    "\n",
    "Podemos agora preparar os dados para criar um conjunto com cada observação.\n",
    "\n",
    "Primeiro, vamos criar uma nova coluna com todo o nome do processo por escrito. Para isso vamos somar a coluna de `sigla` e `num` com um espaço entre elas.\n",
    "\n",
    "Vamos, em seguida, remover o ponto da numeração, para evitar diferentes grafias da mesma informação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   match\n",
       "2  0        ADPF 130\n",
       "4  0        ADPF 130\n",
       "   1        ADPF 130\n",
       "dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_nomeados[\"num\"] = precs_nomeados[\"num\"].str.replace(\".\", \"\")\n",
    "\n",
    "precs = precs_nomeados[\"sigla\"] + \" \" + precs_nomeados[\"num\"]\n",
    "\n",
    "print(type(precs))\n",
    "\n",
    "precs.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa variável `precs` se trata de um objeto series, para contornar isso podemos resetar o índice. Contudo, queremos manter o índice original, já que é a ligação com o DataFrame original.\n",
    "\n",
    "Assim, podemos passar o argumento `level=\"match\"` para manter o índice original e resetar apenas a parte do índice que foi criada pelo `extractall`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ADPF 130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ADPF 130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ADPF 130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match         0\n",
       "2      0  ADPF 130\n",
       "4      0  ADPF 130\n",
       "4      1  ADPF 130"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_df = precs.reset_index(level=\"match\")\n",
    "\n",
    "print(type(precs_df))\n",
    "\n",
    "precs_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pronto agora podemos usar o `merge` para juntar os dois conjuntos de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Relator</th>\n",
       "      <th>Data de publicação</th>\n",
       "      <th>Data de julgamento</th>\n",
       "      <th>Órgão julgador</th>\n",
       "      <th>Ementa</th>\n",
       "      <th>cita_adpf_imprensa</th>\n",
       "      <th>n_cits_cont_concentrado</th>\n",
       "      <th>match</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rcl 63151 MC-Ref</td>\n",
       "      <td>LUIZ FUX</td>\n",
       "      <td>05/12/23</td>\n",
       "      <td>21/11/23</td>\n",
       "      <td>Primeira Turma</td>\n",
       "      <td>EMENTA: REFERENDO NA MEDIDA CAUTELAR NA RECLAM...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ADPF 130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rcl 20757 AgR</td>\n",
       "      <td>NUNES MARQUES</td>\n",
       "      <td>08/02/22</td>\n",
       "      <td>06/12/21</td>\n",
       "      <td>Segunda Turma</td>\n",
       "      <td>Ementa: RECLAMAÇÃO. VEDAÇÃO DE REPUBLICAÇÃO DE...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>ADPF 130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rcl 20757 AgR</td>\n",
       "      <td>NUNES MARQUES</td>\n",
       "      <td>08/02/22</td>\n",
       "      <td>06/12/21</td>\n",
       "      <td>Segunda Turma</td>\n",
       "      <td>Ementa: RECLAMAÇÃO. VEDAÇÃO DE REPUBLICAÇÃO DE...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>ADPF 130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Titulo        Relator Data de publicação Data de julgamento  \\\n",
       "2  Rcl 63151 MC-Ref       LUIZ FUX           05/12/23           21/11/23   \n",
       "4     Rcl 20757 AgR  NUNES MARQUES           08/02/22           06/12/21   \n",
       "4     Rcl 20757 AgR  NUNES MARQUES           08/02/22           06/12/21   \n",
       "\n",
       "   Órgão julgador                                             Ementa  \\\n",
       "2  Primeira Turma  EMENTA: REFERENDO NA MEDIDA CAUTELAR NA RECLAM...   \n",
       "4   Segunda Turma  Ementa: RECLAMAÇÃO. VEDAÇÃO DE REPUBLICAÇÃO DE...   \n",
       "4   Segunda Turma  Ementa: RECLAMAÇÃO. VEDAÇÃO DE REPUBLICAÇÃO DE...   \n",
       "\n",
       "   cita_adpf_imprensa  n_cits_cont_concentrado  match         0  \n",
       "2                   1                        1      0  ADPF 130  \n",
       "4                   1                        4      0  ADPF 130  \n",
       "4                   1                        4      1  ADPF 130  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_com_cits = pd.merge(\n",
    "    df,\n",
    "    precs_df,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "\n",
    "df_com_cits.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão\n",
    "\n",
    "Nessa aula, aprendemos a usar expressões regulares no Pandas para extrair informações de textos. Vimos como podemos usar essa ferramenta para identificar linhas que contenham determinado padrão, o que pode ser relevante para classificar as linhas (criando novas variáveis), contar o número de ocorrências por linha, e até mesmo gerar um novo conjunto de dados para cada informação identificada na linha.\n",
    "\n",
    "Expressões regulares são um recurso muito poderoso para trabalhar com texto, em especial para informações padronizadas. Pense que poderíamos usá-las para identificar datas, diversos números de documentos como CPF, RJ, ou CNPJ, ou extrair informações sobre processos citados em um texto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "abb44a25ac141f9fc3c6de45abf9ef72613fc3eebc8c35ca26f9ad8a6120c4e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
